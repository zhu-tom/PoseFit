{"ast":null,"code":"import _regeneratorRuntime from \"@babel/runtime/regenerator\";\nimport _slicedToArray from \"@babel/runtime/helpers/slicedToArray\";\n\nvar _this = this,\n    _jsxFileName = \"/Users/tom/Sites/cuHacking2021/expo/components/AnalysisScreen.js\";\n\nimport React from 'react';\nimport { Camera } from 'expo-camera';\nimport * as tf from '@tensorflow/tfjs';\nimport * as posenet from '@tensorflow-models/posenet';\nimport { cameraWithTensors } from '@tensorflow/tfjs-react-native';\nimport StyleSheet from \"react-native-web/dist/exports/StyleSheet\";\nimport View from \"react-native-web/dist/exports/View\";\nimport Text from \"react-native-web/dist/exports/Text\";\nimport Button from \"react-native-web/dist/exports/Button\";\nimport Dimensions from \"react-native-web/dist/exports/Dimensions\";\nvar TensorCamera = cameraWithTensors(Camera);\nvar scaleFactor = 0.50;\nvar flipHorizontal = false;\nvar outputStride = 16;\n\nvar convertToMl5 = function convertToMl5(data) {\n  data.keypoints.forEach(function (item) {\n    data[item.part] = {\n      x: item.position.x,\n      y: item.position.y,\n      score: item.score\n    };\n  });\n  return data;\n};\n\nvar AnalysisScreen = function AnalysisScreen(_ref) {\n  var navigation = _ref.navigation;\n\n  var _React$useState = React.useState(false),\n      _React$useState2 = _slicedToArray(_React$useState, 2),\n      tfReady = _React$useState2[0],\n      setTfReady = _React$useState2[1];\n\n  var _React$useState3 = React.useState(null),\n      _React$useState4 = _slicedToArray(_React$useState3, 2),\n      net = _React$useState4[0],\n      setNet = _React$useState4[1];\n\n  React.useEffect(function () {\n    var waitForTf = function waitForTf() {\n      var thenet;\n      return _regeneratorRuntime.async(function waitForTf$(_context) {\n        while (1) {\n          switch (_context.prev = _context.next) {\n            case 0:\n              _context.next = 2;\n              return _regeneratorRuntime.awrap(tf.ready());\n\n            case 2:\n              _context.next = 4;\n              return _regeneratorRuntime.awrap(posenet.load({\n                architecture: 'MobileNetV1',\n                outputStride: outputStride,\n                inputResolution: 257,\n                multiplier: 0.75\n              }));\n\n            case 4:\n              thenet = _context.sent;\n              setTfReady(true);\n              setNet(thenet);\n\n            case 7:\n            case \"end\":\n              return _context.stop();\n          }\n        }\n      }, null, null, null, Promise);\n    };\n\n    waitForTf();\n  }, []);\n\n  var handleCameraStream = function handleCameraStream(images, updatePreview, gl) {\n    var loop = function loop() {\n      var nextImageTensor, pose;\n      return _regeneratorRuntime.async(function loop$(_context2) {\n        while (1) {\n          switch (_context2.prev = _context2.next) {\n            case 0:\n              nextImageTensor = images.next().value;\n              _context2.next = 3;\n              return _regeneratorRuntime.awrap(net.estimateSinglePose(nextImageTensor, scaleFactor, flipHorizontal, outputStride));\n\n            case 3:\n              pose = _context2.sent;\n              console.log(convertToMl5(pose));\n              requestAnimationFrame(loop);\n\n            case 6:\n            case \"end\":\n              return _context2.stop();\n          }\n        }\n      }, null, null, null, Promise);\n    };\n\n    if (tfReady && net !== null) loop();\n  };\n\n  var textureDims;\n\n  if (Platform.OS === 'ios') {\n    textureDims = {\n      height: 1920,\n      width: 1080\n    };\n  } else {\n    textureDims = {\n      height: 1200,\n      width: 1600\n    };\n  }\n\n  return React.createElement(View, {\n    __self: _this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 79,\n      columnNumber: 10\n    }\n  }, React.createElement(TensorCamera, {\n    style: styles.camera,\n    zoom: 0,\n    type: Camera.Constants.Type.front,\n    cameraTextureHeight: textureDims.height,\n    cameraTextureWidth: textureDims.width,\n    resizeHeight: 200,\n    resizeWidth: 152,\n    resizeDepth: 3,\n    onReady: handleCameraStream,\n    autorender: true,\n    __self: _this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 80,\n      columnNumber: 5\n    }\n  }));\n};\n\nvar _Dimensions$get = Dimensions.get(\"window\"),\n    height = _Dimensions$get.height,\n    width = _Dimensions$get.width;\n\nvar styles = StyleSheet.create({\n  camera: {\n    zIndex: 1,\n    width: 350,\n    height: '100%'\n  },\n  cameraView: {\n    flex: 1,\n    height: '100%',\n    width: '100%'\n  }\n});\nexport default AnalysisScreen;","map":{"version":3,"sources":["/Users/tom/Sites/cuHacking2021/expo/components/AnalysisScreen.js"],"names":["React","Camera","tf","posenet","cameraWithTensors","TensorCamera","scaleFactor","flipHorizontal","outputStride","convertToMl5","data","keypoints","forEach","item","part","x","position","y","score","AnalysisScreen","navigation","useState","tfReady","setTfReady","net","setNet","useEffect","waitForTf","ready","load","architecture","inputResolution","multiplier","thenet","handleCameraStream","images","updatePreview","gl","loop","nextImageTensor","next","value","estimateSinglePose","pose","console","log","requestAnimationFrame","textureDims","Platform","OS","height","width","styles","camera","Constants","Type","front","Dimensions","get","StyleSheet","create","zIndex","cameraView","flex"],"mappings":";;;;;;AAAA,OAAOA,KAAP,MAAkB,OAAlB;AACA,SAASC,MAAT,QAAuB,aAAvB;AACA,OAAO,KAAKC,EAAZ,MAAoB,kBAApB;AACA,OAAO,KAAKC,OAAZ,MAAyB,4BAAzB;AACA,SAASC,iBAAT,QAAkC,+BAAlC;;;;;;AAGA,IAAMC,YAAY,GAAGD,iBAAiB,CAACH,MAAD,CAAtC;AACA,IAAMK,WAAW,GAAG,IAApB;AACA,IAAMC,cAAc,GAAG,KAAvB;AACA,IAAMC,YAAY,GAAG,EAArB;;AAEA,IAAMC,YAAY,GAAG,SAAfA,YAAe,CAACC,IAAD,EAAU;AAC7BA,EAAAA,IAAI,CAACC,SAAL,CAAeC,OAAf,CAAuB,UAAAC,IAAI,EAAI;AAC7BH,IAAAA,IAAI,CAACG,IAAI,CAACC,IAAN,CAAJ,GAAkB;AAChBC,MAAAA,CAAC,EAAEF,IAAI,CAACG,QAAL,CAAcD,CADD;AAEhBE,MAAAA,CAAC,EAAEJ,IAAI,CAACG,QAAL,CAAcC,CAFD;AAGhBC,MAAAA,KAAK,EAAEL,IAAI,CAACK;AAHI,KAAlB;AAKD,GAND;AAOA,SAAOR,IAAP;AACD,CATD;;AAWA,IAAMS,cAAc,GAAG,SAAjBA,cAAiB,OAAkB;AAAA,MAAhBC,UAAgB,QAAhBA,UAAgB;;AAAA,wBACTpB,KAAK,CAACqB,QAAN,CAAe,KAAf,CADS;AAAA;AAAA,MAChCC,OADgC;AAAA,MACvBC,UADuB;;AAAA,yBAEjBvB,KAAK,CAACqB,QAAN,CAAe,IAAf,CAFiB;AAAA;AAAA,MAEhCG,GAFgC;AAAA,MAE3BC,MAF2B;;AAIvCzB,EAAAA,KAAK,CAAC0B,SAAN,CAAgB,YAAM;AACpB,QAAMC,SAAS,GAAG,SAAZA,SAAY;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,+CACVzB,EAAE,CAAC0B,KAAH,EADU;;AAAA;AAAA;AAAA,+CAEKzB,OAAO,CAAC0B,IAAR,CAAa;AAChCC,gBAAAA,YAAY,EAAE,aADkB;AAEhCtB,gBAAAA,YAAY,EAAZA,YAFgC;AAGhCuB,gBAAAA,eAAe,EAAE,GAHe;AAIhCC,gBAAAA,UAAU,EAAE;AAJoB,eAAb,CAFL;;AAAA;AAEVC,cAAAA,MAFU;AAQhBV,cAAAA,UAAU,CAAC,IAAD,CAAV;AACAE,cAAAA,MAAM,CAACQ,MAAD,CAAN;;AATgB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KAAlB;;AAWAN,IAAAA,SAAS;AACV,GAbD,EAaG,EAbH;;AAeA,MAAMO,kBAAkB,GAAG,SAArBA,kBAAqB,CAACC,MAAD,EAASC,aAAT,EAAwBC,EAAxB,EAA+B;AACxD,QAAMC,IAAI,GAAG,SAAPA,IAAO;AAAA;AAAA;AAAA;AAAA;AAAA;AACLC,cAAAA,eADK,GACaJ,MAAM,CAACK,IAAP,GAAcC,KAD3B;AAAA;AAAA,+CAGQjB,GAAG,CAACkB,kBAAJ,CAAuBH,eAAvB,EAAwCjC,WAAxC,EAAqDC,cAArD,EAAqEC,YAArE,CAHR;;AAAA;AAGLmC,cAAAA,IAHK;AAIXC,cAAAA,OAAO,CAACC,GAAR,CAAYpC,YAAY,CAACkC,IAAD,CAAxB;AAQAG,cAAAA,qBAAqB,CAACR,IAAD,CAArB;;AAZW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KAAb;;AAcA,QAAIhB,OAAO,IAAIE,GAAG,KAAK,IAAvB,EAA6Bc,IAAI;AAClC,GAhBD;;AAuBA,MAAIS,WAAJ;;AACA,MAAIC,QAAQ,CAACC,EAAT,KAAgB,KAApB,EAA2B;AAC3BF,IAAAA,WAAW,GAAG;AACZG,MAAAA,MAAM,EAAE,IADI;AAEZC,MAAAA,KAAK,EAAE;AAFK,KAAd;AAIC,GALD,MAKO;AACPJ,IAAAA,WAAW,GAAG;AACZG,MAAAA,MAAM,EAAE,IADI;AAEZC,MAAAA,KAAK,EAAE;AAFK,KAAd;AAIC;;AAED,SAAO,oBAAC,IAAD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KACL,oBAAC,YAAD;AAEA,IAAA,KAAK,EAAEC,MAAM,CAACC,MAFd;AAGA,IAAA,IAAI,EAAE,CAHN;AAIA,IAAA,IAAI,EAAEpD,MAAM,CAACqD,SAAP,CAAiBC,IAAjB,CAAsBC,KAJ5B;AAMA,IAAA,mBAAmB,EAAET,WAAW,CAACG,MANjC;AAOA,IAAA,kBAAkB,EAAEH,WAAW,CAACI,KAPhC;AAQA,IAAA,YAAY,EAAE,GARd;AASA,IAAA,WAAW,EAAE,GATb;AAUA,IAAA,WAAW,EAAE,CAVb;AAWA,IAAA,OAAO,EAAEjB,kBAXT;AAYA,IAAA,UAAU,EAAE,IAZZ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IADK,CAAP;AAgBD,CAvED;;sBAyEwBuB,UAAU,CAACC,GAAX,CAAe,QAAf,C;IAAjBR,M,mBAAAA,M;IAAQC,K,mBAAAA,K;;AAEf,IAAMC,MAAM,GAAGO,UAAU,CAACC,MAAX,CAAkB;AAC/BP,EAAAA,MAAM,EAAE;AACNQ,IAAAA,MAAM,EAAE,CADF;AAENV,IAAAA,KAAK,EAAE,GAFD;AAGND,IAAAA,MAAM,EAAE;AAHF,GADuB;AAM/BY,EAAAA,UAAU,EAAE;AACVC,IAAAA,IAAI,EAAE,CADI;AAEVb,IAAAA,MAAM,EAAE,MAFE;AAGVC,IAAAA,KAAK,EAAE;AAHG;AANmB,CAAlB,CAAf;AAaA,eAAehC,cAAf","sourcesContent":["import React from 'react';\nimport { Camera } from 'expo-camera';\nimport * as tf from '@tensorflow/tfjs';\nimport * as posenet from '@tensorflow-models/posenet';\nimport { cameraWithTensors } from '@tensorflow/tfjs-react-native';\nimport { StyleSheet, View, Text, Button, Dimensions } from 'react-native';\n\nconst TensorCamera = cameraWithTensors(Camera);\nconst scaleFactor = 0.50;\nconst flipHorizontal = false;\nconst outputStride = 16;\n\nconst convertToMl5 = (data) => {\n  data.keypoints.forEach(item => {\n    data[item.part] = {\n      x: item.position.x,\n      y: item.position.y,\n      score: item.score,\n    }\n  });\n  return data;\n}\n\nconst AnalysisScreen = ({navigation}) => {\n  const [tfReady, setTfReady] = React.useState(false);\n  const [net, setNet] = React.useState(null);\n\n  React.useEffect(() => {\n    const waitForTf = async () => {\n      await tf.ready();\n      const thenet = await posenet.load({\n        architecture: 'MobileNetV1',\n        outputStride,\n        inputResolution: 257,\n        multiplier: 0.75,\n      });\n      setTfReady(true);\n      setNet(thenet);\n    }\n    waitForTf();\n  }, [])\n\n  const handleCameraStream = (images, updatePreview, gl) => {\n    const loop = async () => {\n      const nextImageTensor = images.next().value\n      \n      const pose = await net.estimateSinglePose(nextImageTensor, scaleFactor, flipHorizontal, outputStride);\n      console.log(convertToMl5(pose));\n      //\n      // do something with tensor here\n      //\n\n      // if autorender is false you need the following two lines.\n      // updatePreview();\n      // gl.endFrameEXP();\n      requestAnimationFrame(loop);\n    }\n    if (tfReady && net !== null) loop();\n  }\n\n\n  // Currently expo does not support automatically determining the\n  // resolution of the camera texture used. So it must be determined\n  // empirically for the supported devices and preview size.\n\n  let textureDims;\n  if (Platform.OS === 'ios') {\n  textureDims = {\n    height: 1920,\n    width: 1080,\n  };\n  } else {\n  textureDims = {\n    height: 1200,\n    width: 1600,\n  };\n  }\n\n  return <View>\n    <TensorCamera\n    // Standard Camera props\n    style={styles.camera}\n    zoom={0}\n    type={Camera.Constants.Type.front}\n    // Tensor related props\n    cameraTextureHeight={textureDims.height}\n    cameraTextureWidth={textureDims.width}\n    resizeHeight={200}\n    resizeWidth={152}\n    resizeDepth={3}\n    onReady={handleCameraStream}\n    autorender={true}\n    />\n  </View>\n}\n\nconst {height, width} = Dimensions.get(\"window\");\n\nconst styles = StyleSheet.create({\n  camera: {\n    zIndex: 1,\n    width: 350,\n    height: '100%',\n  },\n  cameraView: {\n    flex: 1,\n    height: '100%',\n    width: '100%'\n  }\n});\n\nexport default AnalysisScreen;"]},"metadata":{},"sourceType":"module"}